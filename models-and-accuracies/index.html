<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Models and Accuracies - OpenFace</title>
        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.5.0.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../css/highlight.css">
        <link href="../css/extra.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->
	
	<script src="../js/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/highlight.pack.js"></script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="..">OpenFace</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                    <li >
                        <a href="..">Home</a>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Demos <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../demo-1-web/">Demo 1 - Real-time Web</a>
</li>
                            
<li >
    <a href="../demo-2-comparison/">Demo 2 - Comparison</a>
</li>
                            
<li >
    <a href="../demo-3-classifier/">Demo 3 - Training a Classifier</a>
</li>
                            
<li >
    <a href="../demo-4-sphere/">Demo 4 - Real-time Sphere Visualization</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li >
    <a href="../usage/">Usage and API Docs</a>
</li>
                            
<li >
    <a href="../setup/">Setup</a>
</li>
                            
<li >
    <a href="../faq/">FAQ</a>
</li>
                        </ul>
                    </li>
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">DNN Models <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                            
<li class="active">
    <a href="./">Models and Accuracies</a>
</li>
                            
<li >
    <a href="../training-new-models/">Training a DNN Model</a>
</li>
                            
<li >
    <a href="../visualizations/">Visualizations</a>
</li>
                        </ul>
                    </li>
                    <li >
                        <a href="../release-notes/">Release Notes</a>
                    </li>
                </ul>

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                    <li >
                        <a rel="next" href="../faq/">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../training-new-models/">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/cmusatyalab/openface">
                                <i class="fa fa-github"></i>GitHub
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#models-and-accuracies">Models and Accuracies</a></li>
        <li class="main "><a href="#model-definitions">Model Definitions</a></li>
        <li class="main "><a href="#pre-trained-models">Pre-trained Models</a></li>
            <li><a href="#performance">Performance</a></li>
            <li><a href="#accuracy-on-the-lfw-benchmark">Accuracy on the LFW Benchmark</a></li>
            <li><a href="#running-the-lfw-experiment">Running The LFW Experiment</a></li>
        <li class="main "><a href="#projects-with-higher-accuracy">Projects with Higher Accuracy</a></li>
            <li><a href="#oxfords-vgg-face-descriptor">Oxford's VGG Face Descriptor</a></li>
            <li><a href="#deep-face-representation">Deep Face Representation</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="models-and-accuracies">Models and Accuracies</h1>
<p>This page overviews different OpenFace neural network models
and is intended for advanced users.</p>
<h1 id="model-definitions">Model Definitions</h1>
<p>The number of parameters are with 128-dimensional embeddings
and do not include the batch normalization running means and
variances.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Number of Parameters</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/cmusatyalab/openface/blob/master/models/openface/nn4.small2.def.lua">nn4.small2</a></td>
<td>3733968</td>
</tr>
<tr>
<td><a href="https://github.com/cmusatyalab/openface/blob/master/models/openface/nn4.small1.def.lua">nn4.small1</a></td>
<td>5579520</td>
</tr>
<tr>
<td><a href="https://github.com/cmusatyalab/openface/blob/master/models/openface/nn4.def.lua">nn4</a></td>
<td>6959088</td>
</tr>
<tr>
<td><a href="https://github.com/cmusatyalab/openface/blob/master/models/openface/nn2.def.lua">nn2</a></td>
<td>7472144</td>
</tr>
</tbody>
</table>
<h1 id="pre-trained-models">Pre-trained Models</h1>
<p>Models can be trained in different ways with different datasets.
Pre-trained models are versioned and should be released with
a corresponding model definition.
Switch between models with caution because the embeddings
not compatible with each other.</p>
<p>The current models are trained with a combination of the two largest
(of August 2015) publicly-available face recognition datasets based on names:
<a href="http://vintage.winklerbros.net/facescrub.html">FaceScrub</a>
and <a href="http://arxiv.org/abs/1411.7923">CASIA-WebFace</a>.</p>
<p>The models can be downloaded from our storage servers:</p>
<ul>
<li><a href="https://storage.cmusatyalab.org/openface-models/nn4.v1.t7">nn4.v1</a></li>
<li><a href="https://storage.cmusatyalab.org/openface-models/nn4.v2.t7">nn4.v2</a></li>
<li><a href="https://storage.cmusatyalab.org/openface-models/nn4.small1.v1.t7">nn4.small1.v1</a></li>
<li><a href="https://storage.cmusatyalab.org/openface-models/nn4.small2.v1.t7">nn4.small2.v1</a></li>
</ul>
<p>API differences between the models are:</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>alignment <code>landmarkIndices</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>nn4.v1</td>
<td><code>openface.AlignDlib.INNER_EYES_AND_BOTTOM_LIP</code></td>
</tr>
<tr>
<td>nn4.v2</td>
<td><code>openface.AlignDlib.OUTER_EYES_AND_NOSE</code></td>
</tr>
<tr>
<td>nn4.small1.v1</td>
<td><code>openface.AlignDlib.OUTER_EYES_AND_NOSE</code></td>
</tr>
<tr>
<td>nn4.small2.v1</td>
<td><code>openface.AlignDlib.OUTER_EYES_AND_NOSE</code></td>
</tr>
</tbody>
</table>
<h2 id="performance">Performance</h2>
<p>The performance is measured by averaging 500 forward passes with
<a href="https://github.com/cmusatyalab/openface/blob/master/util/profile-network.lua">util/profile-network.lua</a>
and the following results use OpenBLAS on an 8 core 3.70 GHz CPU
and a Tesla K40 GPU.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Runtime (CPU)</th>
<th>Runtime (GPU)</th>
</tr>
</thead>
<tbody>
<tr>
<td>nn4.v1</td>
<td>75.67 ms &plusmn; 19.97 ms</td>
<td>21.96 ms &plusmn; 6.71 ms</td>
</tr>
<tr>
<td>nn4.v2</td>
<td>82.74 ms &plusmn; 19.96 ms</td>
<td>20.82 ms &plusmn; 6.03 ms</td>
</tr>
<tr>
<td>nn4.small1.v1</td>
<td>69.58 ms &plusmn; 16.17 ms</td>
<td>15.90 ms &plusmn; 5.18 ms</td>
</tr>
<tr>
<td>nn4.small2.v1</td>
<td>58.9 ms &plusmn; 15.36 ms</td>
<td>13.72 ms &plusmn; 4.64 ms</td>
</tr>
</tbody>
</table>
<h2 id="accuracy-on-the-lfw-benchmark">Accuracy on the LFW Benchmark</h2>
<p>Even though the public datasets we trained on have orders of magnitude less data
than private industry datasets, the accuracy is remarkably high
on the standard
<a href="http://vis-www.cs.umass.edu/lfw/results.html">LFW</a>
benchmark.
We had to fallback to using the deep funneled versions for
58 of 13233 images because dlib failed to detect a face or landmarks.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Accuracy</th>
<th>AUC</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>nn4.small2.v1</strong> (Default)</td>
<td>0.9292 &plusmn; 0.0134</td>
<td>0.973</td>
</tr>
<tr>
<td>nn4.small1.v1</td>
<td>0.9210 &plusmn; 0.0160</td>
<td>0.973</td>
</tr>
<tr>
<td>nn4.v2</td>
<td>0.9157 &plusmn; 0.0152</td>
<td>0.966</td>
</tr>
<tr>
<td>nn4.v1</td>
<td>0.7612 &plusmn; 0.0189</td>
<td>0.853</td>
</tr>
<tr>
<td>FaceNet Paper (Reference)</td>
<td>0.9963 ± 0.009</td>
<td>not provided</td>
</tr>
</tbody>
</table>
<h3 id="roc-curves">ROC Curves</h3>
<h4 id="nn4small2v1">nn4.small2.v1</h4>
<p><img alt="" src="https://raw.githubusercontent.com/cmusatyalab/openface/master/evaluation/lfw.nn4.small2.v1/roc.png" /></p>
<h4 id="nn4small1v1">nn4.small1.v1</h4>
<p><img alt="" src="https://raw.githubusercontent.com/cmusatyalab/openface/master/evaluation/lfw.nn4.small1.v1/roc.png" /></p>
<h4 id="nn4v2">nn4.v2</h4>
<p><img alt="" src="https://raw.githubusercontent.com/cmusatyalab/openface/master/evaluation/lfw.nn4.v2/roc.png" /></p>
<h4 id="nn4v1">nn4.v1</h4>
<p><img alt="" src="https://raw.githubusercontent.com/cmusatyalab/openface/master/evaluation/lfw.nn4.v1/roc.png" /></p>
<h2 id="running-the-lfw-experiment">Running The LFW Experiment</h2>
<p>This can be generated with the following commands from the root <code>openface</code>
directory, assuming you have downloaded and placed the raw and
<a href="http://vis-www.cs.umass.edu/deep_funnel.html">deep funneled</a>
LFW data from <a href="http://vis-www.cs.umass.edu/lfw/">here</a>
in <code>./data/lfw/raw</code> and <code>./data/lfw/deepfunneled</code>.
Also save <a href="http://vis-www.cs.umass.edu/lfw/pairs.txt">pairs.txt</a> in
<code>./data/lfw/pairs.txt</code>.</p>
<ol>
<li>Install prerequisites as below.</li>
<li>Preprocess the raw <code>lfw</code> images, change <code>8</code> to however many
   separate processes you want to run:
   <code>for N in {1..8}; do ./util/align-dlib.py data/lfw/raw align outerEyesAndNose data/lfw/dlib-affine-sz:96 --size 96 &amp; done</code>.
   Fallback to deep funneled versions for images that dlib failed
   to align:
   <code>./util/align-dlib.py data/lfw/raw align outerEyesAndNose data/lfw/dlib-affine-sz:96 --size 96 --fallbackLfw data/lfw/deepfunneled</code></li>
<li>Generate representations with <code>./batch-represent/main.lua -outDir evaluation/lfw.nn4.small2.v1.reps -model models/openface/nn4.small2.v1.t7 -data data/lfw/dlib-affine-sz:96</code></li>
<li>Generate the ROC curve from the <code>evaluation</code> directory with <code>./lfw.py nn4.small2.v1 lfw.nn4.small2.v1.reps</code>.
   This creates <code>roc.pdf</code> in the <code>lfw.nn4.small2.v1.reps</code> directory.</li>
</ol>
<h1 id="projects-with-higher-accuracy">Projects with Higher Accuracy</h1>
<p>If you're interested in higher accuracy open source code, see:</p>
<h2 id="oxfords-vgg-face-descriptor"><a href="http://www.robots.ox.ac.uk/~vgg/software/vgg_face/">Oxford's VGG Face Descriptor</a></h2>
<p>This is licensed for non-commercial research purposes.
They've released their softmax network, which obtains .9727 accuracy
on the LFW and will release their triplet network (0.9913 accuracy)
and data soon (?).</p>
<p>Their softmax model doesn't embed features like FaceNet,
which makes tasks like classification and clustering more difficult.
Their triplet model hasn't yet been released, but will provide
embeddings similar to FaceNet.
The triplet model will be supported by OpenFace once it's released.</p>
<h2 id="deep-face-representation"><a href="https://github.com/AlfredXiangWu/face_verification_experiment">Deep Face Representation</a></h2>
<p>This uses Caffe and doesn't yet have a license.
The accuracy on the LFW is .9777.
This model doesn't embed features like FaceNet,
which makes tasks like classification and clustering more difficult.</p></div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Crafted by <a href="http://bamos.github.io">Brandon Amos</a> at Carnegie Mellon University.</p>
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>var base_url = '..';</script>
        <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>
        <script src="../js/base.js"></script>
        <script src="../js/sp.js"></script>
        <script src="../js/extra.js"></script><div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
